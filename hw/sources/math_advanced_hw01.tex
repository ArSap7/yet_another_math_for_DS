%!TEX TS-program = xelatex
\documentclass[12pt, a4paper, oneside]{article}

% Можно вставить разную преамбулу
\input{preamble}

\usepackage{amssymb,fge}
\newcommand{\mysetminus}{\mathbin{\fgebackslash}}

\title{Yet Another Math for DS Course \\ Домашка №1}
\date{}
\author{Матричное дифФфФфФференцирование \\ (продвинутая группа)}

\begin{document}

\maketitle

\epigraph{ $\bigg(\text{ \includegraphics[scale=0.08]{tree1.png}} \bigg)^T = $  \includegraphics[scale=0.08]{tree2.png} }{<<Джек и бобовый стебель>> (1890)}

Добро пожаловать в первую домашку. Для вашего удобства она разбита на три части. В первой находятся совсем простые задачи. Если вы решите их идеально, вы наберёте $50$ баллов из $100.$ Решая только первый раздел из каждой домашки, вы будете уверенно двигаться к троечке. Если вы претендуете на большее, для вас есть разделы с более сложными задачами. 

Решение работы нужно сдать в виде pdf-файла. Решения должны быть оформлены на листочке аккуратным почерком либо затеханы на компьютере. Если у вас плохой почерк, домашка должна быть затехана. Затехать домашку можно в overleaf, typora, colab или другом любом удобном для вас сервисе.

\section*{Задачи на троечку}

Если вы идеально решаете все задачи из этого раздела, вы получаете $50$ баллов из $100$.

\begin{problem}{30}
    Найдите производные $\nabla_X f(X)$ следующих функций
    
    \begin{enumerate}
        \item  $f(X) = \tr(AX^TXBX^{-T}),$ где  $A, X, B \in \RR^{n \times n}$ 
        
        \item  $f(X) = \tr(AXB),$ где $A \in \RR^{p \times m}, B \in \RR^{n \times p}, X  \in \RR^{m \times n}.$ 
        
        \item  $f(X) = \det(X^TAX),$ где  $A, X \in \RR^{n \times n}.$ 
    \end{enumerate}
\end{problem}

\begin{problem}{10}
    Пусть $f(X) = \ln \det X,$ где $X \in \mathbb{R}^{n\times n}$. Найдите производную $\nabla_X f(X)$.
\end{problem}

\newpage

\begin{problem}{10}
Решите следующую задачу матричной оптимизации. При решении считайте, что матрица $A$ положительно определена.

\[
f(x) = x^T A x - x^Tb + c \to \min_{x}
\]
\end{problem}


\section*{Задачи на хор}

Если вы идеально решаете ещё и этот раздел, вы получаете $70$ баллов из $100$.

\begin{problem}{20}
    Предположим, что мы хотим обучить ridge-регрессию, но в качестве регуляризатора решили взять видоизменённую норму ($S$ -- некоторая фиксированная симметричная положительно-определённая матрица):
    
    \[
    L(w) = (y - Xw)^T \cdot (y-Xw) + ||Sw||^2_2.
    \]
    
    Найдите градиент $\nabla_w L(w)$ получившейся функции потерь. Чему будет равно оптимальное значение весов в этом случае? Проверьте, что найденное значение действительно является точкой минимума. 
\end{problem}


\section*{Задачи на отл}

Если вы идеально решаете ещё и этот раздел, вы получаете $90$ баллов из $100$.

\begin{problem}{10}
    Рассмотрим симметричную матрицу $A \in \mathbb{R}^{n \times n}$ и ее спектральное разложение $A = Q \Lambda Q^T$.
    Пусть $\lambda \in \mathbb{R}^n$ - это диагональ матрицы $\Lambda$ (то есть вектор, составленный из собственных значений $A$).
    Найдите производные:
    
    \begin{enumerate}
        \item $\nabla_{\lambda} \tr(A)$
        \item $\nabla_Q \tr(A)$
    \end{enumerate}
\end{problem}

\begin{problem}{10}
Пусть $x \in \RR^n \mysetminus \{0\}.$ Найдите $\nabla_x f(x)$ для \[f(x) = \langle x, x \rangle^{\langle x, x \rangle}.\]
\end{problem}


\section*{Задачи на десяточку}

Если вы идеально решаете ещё и этот раздел, вы выбиваете $100$ из $100$. Вы большой молодец. 

\begin{problem}{10}
    Рассмотрим целевую функцию логистической регрессии 
    \[
    Q(w) = \frac{1}{n} \sum_{i=1}^{n} \log (1 + \exp(-y_i \, \langle w, x_i\rangle)),
    \]
    
    \begin{enumerate} 
        \item Найдите градиент $\nabla Q_w$ и упростите итоговое выражение таким образом, чтобы в нём участвовала сигмоидная функция 
        $$\sigma(z) = \frac{1}{1 + \exp(-z)}.$$ При решении данной задачи вам может понадобиться следующий факт (убедитесь, что он действительно выполняется):
        $$\sigma'(z) = \sigma(z) (1- \sigma(z)).$$ 
        \item Выпишите, как будет выглядеть шаг градиентного спуска.
        \item Найдите вторую производную целевой функции по $w$.
        \item Выпишите квадратичную аппроксимацию для $Q(w)$ в окрестности $w=0$. Для этого разложите функцию потерь в ряд Тейлора до второго члена в окрестности точки $w=0$. С какой задачей совпадает задача минимизации квадратичной аппроксимации?
    \end{enumerate} 
\end{problem}

\end{document}
